{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fcdf4bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow import keras \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0ecee027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Physical GPUs, 10 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB * 2 of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024 * 2)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd8f153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(root, vfold_ratio=0.2, max_items_per_class= 10000 ):\n",
    "    all_files = glob.glob(os.path.join(root, '*.npy'))\n",
    "\n",
    "    #initialize variables \n",
    "    x = np.empty([0, 784])\n",
    "    y = np.empty([0])\n",
    "    class_names = []\n",
    "\n",
    "    #load a subset of the data to memory \n",
    "    for idx, file in enumerate(all_files):\n",
    "        data = np.load(file)\n",
    "        data = data[0: max_items_per_class, :]\n",
    "        labels = np.full(data.shape[0], idx)\n",
    "\n",
    "        x = np.concatenate((x, data), axis=0)\n",
    "        y = np.append(y, labels)\n",
    "\n",
    "        class_name, ext = os.path.splitext(os.path.basename(file))\n",
    "        class_names.append(class_name)\n",
    "\n",
    "    data = None\n",
    "    labels = None\n",
    "\n",
    "    #separate into training and testing \n",
    "    permutation = np.random.permutation(y.shape[0])\n",
    "    x = x[permutation, :]\n",
    "    y = y[permutation]\n",
    "\n",
    "    vfold_size = int(x.shape[0]/100*(vfold_ratio*100))\n",
    "\n",
    "    x_test = x[0:vfold_size, :]\n",
    "    y_test = y[0:vfold_size]\n",
    "\n",
    "    x_train = x[vfold_size:x.shape[0], :]\n",
    "    y_train = y[vfold_size:y.shape[0]]\n",
    "    return x_train, y_train, x_test, y_test, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "74f8d636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['duck', 'snail', 'banana', 'broccoli', 'carrot', 'bird', 'fish', 'watermelon', 'cloud', 'apple', 'blackberry', 'pig', 'cow', 'bush', 'leaf', 'flamingo', 'zebra', 'octopus', 'ant', 'grass', 'donut', 'kangaroo', 'blueberry', 'parrot', 'raccoon', 'camel', 'frog', 'spider', 'pear', 'crab', 'garden', 'sandwich', 'asparagus', 'flower', 'mouse', 'swan', 'steak', 'potato', 'crocodile', 'owl', 'horse', 'strawberry', 'grapes', 'pineapple', 'cake', 'bread']\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test, class_names = load_data(\"./data\")\n",
    "print(class_names)\n",
    "image_size = 28\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Reshape and normalize\n",
    "x_train = x_train.reshape(x_train.shape[0], image_size, image_size, 1).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], image_size, image_size, 1).astype('float32')\n",
    "\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "\n",
    "# Convert class vectors to class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2e4e5180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 14, 14, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               73856     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 46)                5934      \n",
      "=================================================================\n",
      "Total params: 103,086\n",
      "Trainable params: 103,086\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Convolution2D(16, (3, 3),\n",
    "                        padding='same',\n",
    "                        input_shape=x_train.shape[1:], activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Convolution2D(32, (3, 3), padding='same', activation= 'relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Convolution2D(64, (3, 3), padding='same', activation= 'relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size =(2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax')) \n",
    "# Train model\n",
    "adam = tf.optimizers.Adam()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['top_k_categorical_accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0b1382af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 331200 samples, validate on 36800 samples\n",
      "Epoch 1/5\n",
      "331200/331200 - 5s - loss: 1.6175 - top_k_categorical_accuracy: 0.8284 - val_loss: 1.1974 - val_top_k_categorical_accuracy: 0.8997\n",
      "Epoch 2/5\n",
      "331200/331200 - 4s - loss: 1.1028 - top_k_categorical_accuracy: 0.9109 - val_loss: 1.0481 - val_top_k_categorical_accuracy: 0.9171\n",
      "Epoch 3/5\n",
      "331200/331200 - 4s - loss: 0.9828 - top_k_categorical_accuracy: 0.9243 - val_loss: 0.9558 - val_top_k_categorical_accuracy: 0.9262\n",
      "Epoch 4/5\n",
      "331200/331200 - 4s - loss: 0.9168 - top_k_categorical_accuracy: 0.9310 - val_loss: 0.9288 - val_top_k_categorical_accuracy: 0.9293\n",
      "Epoch 5/5\n",
      "331200/331200 - 4s - loss: 0.8721 - top_k_categorical_accuracy: 0.9357 - val_loss: 0.9070 - val_top_k_categorical_accuracy: 0.9332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f605c1f4310>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model \n",
    "model.fit(x = x_train, y = y_train, validation_split=0.1, batch_size = 256, verbose=2, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7848c902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuarcy: 93.14%\n"
     ]
    }
   ],
   "source": [
    "#evaluate on unseen data\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuarcy: {:0.2f}%'.format(score[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "24c4abc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('QuickDraw.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a893096d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QuickDraw",
   "language": "python",
   "name": "quickdraw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
